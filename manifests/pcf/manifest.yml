addons: []
instance_groups:
- azs:
  - ap-northeast-1a
  env:
    bosh:
      password: $6$cb459058f1878808$/w85mSXdX//Jp1Gil6E1l3du9PE8ipXD/wa7bNGDoyTa3vD82yyobIyrbHpw/syuhuEWY4QNXHhNwRmRjkj9N.
  instances: 1
  jobs:
  - consumes:
      mysql:
        from: mysql
    name: pxc-mysql
    properties:
      admin_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_admin_password.password))
      admin_username: admin
      engine_config:
        binlog:
          space_limit_percent: 50
        galera:
          cluster_name: grafana_db
          enabled: true
      pxc_enabled: true
      remote_admin_access: true
      roadmin_enabled: true
      roadmin_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/roadmin_password.value))
      seeded_databases:
      - name: grafana
        password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_user.password))
        username: grafana
      tls:
        client:
          ca: |
            -----BEGIN CERTIFICATE-----
            MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
            CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
            MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
            dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
            FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
            yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
            P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
            w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
            46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
            xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
            MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
            AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
            BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
            YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
            Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
            wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
            Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
            +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
            -----END CERTIFICATE-----
        galera:
          ca: |
            -----BEGIN CERTIFICATE-----
            MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
            CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
            MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
            dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
            FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
            yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
            P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
            w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
            46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
            xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
            MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
            AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
            BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
            YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
            Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
            wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
            Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
            +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
            -----END CERTIFICATE-----
          certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_certificate.cert_pem))
          private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_certificate.private_key_pem))
        server:
          ca: |
            -----BEGIN CERTIFICATE-----
            MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
            CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
            MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
            dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
            FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
            yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
            P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
            w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
            46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
            xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
            MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
            AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
            BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
            YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
            Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
            wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
            Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
            +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
            -----END CERTIFICATE-----
          certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_certificate.cert_pem))
          private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_certificate.private_key_pem))
    provides:
      mysql:
        as: mysql
    release: pxc
  - consumes: {}
    name: cluster-health-logger
    properties:
      db_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_cluster_health_password.value))
    provides: {}
    release: pxc
  - consumes: {}
    name: galera-agent
    properties:
      db_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_mysql_galera_healthcheck_db_password.value))
      endpoint_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc/mysql_mysql_galera_healthcheck_endpoint_password.value))
    provides:
      galera-agent:
        as: galera-agent
    release: pxc
  - consumes: {}
    name: gra-log-purger
    provides: {}
    release: pxc
  - consumes: {}
    name: bootstrap
    provides: {}
    release: pxc
  - consumes: {}
    name: bpm
    provides: {}
    release: bpm
  lifecycle: service
  name: pxc
  networks:
  - default:
    - dns
    - gateway
    name: tas-pcf-subnet-1
  persistent_disk_type: "10240"
  properties: {}
  stemcell: bosh-aws-xen-hvm-ubuntu-xenial-go_agent
  update:
    max_in_flight: 5
  vm_type: c5.large
- azs:
  - ap-northeast-1a
  env:
    bosh:
      password: $6$e5256d1df5b5a391$z7dAsgjlJGsC./Wo8psBtDZz2WNk7WSE.O.GXudS9WrI4.U4clLDAez70B7gUcLHhH7ImHnQykHyC80oCqD0F0
  instances: 1
  jobs:
  - consumes: {}
    name: proxy
    properties:
      api_force_https: true
      api_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/pxc-proxy/mysql_proxy_api_password.value))
    provides:
      mysql-database:
        as: mysql-database
      proxy:
        as: proxy
    release: pxc
  - consumes: {}
    name: bpm
    provides: {}
    release: bpm
  lifecycle: service
  name: pxc-proxy
  networks:
  - default:
    - dns
    - gateway
    name: tas-pcf-subnet-1
  persistent_disk_type: "5120"
  properties: {}
  stemcell: bosh-aws-xen-hvm-ubuntu-xenial-go_agent
  update:
    max_in_flight: 5
  vm_type: c5.large
- azs:
  - ap-northeast-1a
  env:
    bosh:
      password: $6$c91eca998b47bd84$GcL5zpeCC3EznJnJXpMUcqyA5n8.g/RWU0zS2jMH747qmiJt3FwQBcUdvBSOSBtGc0ZT6j57RkUKo28mJihTg0
  instances: 2
  jobs:
  - consumes: {}
    name: blackbox-exporter
    properties:
      blackbox:
        history_limit: 100
        listen_address: 127.0.0.1:9115
        log_level: info
    provides: {}
    release: prometheus
  - consumes: {}
    name: bpm
    provides: {}
    release: bpm
  - consumes:
      tsdb-nginx:
        deployment: p-healthwatch2-f1b02b35a93fdf6e7a9f
        from: tsdb-nginx
    name: smoke-test
    properties:
      healthwatch_deployment_name: p-healthwatch2-f1b02b35a93fdf6e7a9f
      healthwatch_network_name: tas-pcf-subnet-1
      job_name: grafana
      promxy:
        tls:
          ca: |
            -----BEGIN CERTIFICATE-----
            MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
            CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
            MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
            dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
            FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
            yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
            P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
            w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
            46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
            xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
            MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
            AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
            BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
            YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
            Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
            wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
            Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
            +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
            -----END CERTIFICATE-----
          certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/promxy_client_mtls.cert_pem))
          private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/promxy_client_mtls.private_key_pem))
          server_name: promxy
    provides: {}
    release: healthwatch-smoke-test
  - consumes: {}
    name: pks-cluster-discovery
    properties:
      metrics:
        tls:
          ca: |
            -----BEGIN CERTIFICATE-----
            MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
            CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
            MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
            dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
            FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
            yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
            P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
            w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
            46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
            xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
            MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
            AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
            BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
            YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
            Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
            wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
            Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
            +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
            -----END CERTIFICATE-----
          certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/cluster_discovery_server_mtls.cert_pem))
          private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/cluster_discovery_server_mtls.private_key_pem))
      pks_cluster_discovery:
        enabled: false
        prometheus:
          scrape_configs:
            pks_cluster_discovery:
              enabled: false
    provides: {}
    release: pks-cluster-discovery
  - consumes:
      tsdb-nginx:
        from: tsdb-nginx
    name: prometheus
    properties:
      alertmanager:
        port: 9097
        tls_config:
          ca: |
            -----BEGIN CERTIFICATE-----
            MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
            CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
            MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
            dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
            FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
            yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
            P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
            w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
            46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
            xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
            MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
            AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
            BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
            YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
            Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
            wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
            Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
            +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
            -----END CERTIFICATE-----
          certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alertmanager_client_mtls.cert_pem))
          key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alertmanager_client_mtls.private_key_pem))
      grafana:
        root_url: http://grafana.leedh.cloud:443
        tls:
          ca: null
          certificate: null
      healthwatch:
        disk_chunk_size: 6144
        memory_chunk_size: 4096
      instance_count: 2
      pks_cluster_discovery:
        enabled: false
        prometheus:
          scrape_configs:
            pks_cluster_discovery:
              enabled: false
      prometheus:
        alerting_rules: |-
          groups:
            ##### BEGIN FOUNDATION ALERTING RULES #####
            - name: BOSHDirectorHealth
              rules:
                - alert: BOSHDirectorStatus
                  expr: 'increase(bosh_sli_failures_total{scrape_instance_group="bosh-health-exporter"}[20m]) > 0'
                  for: 20m
                  annotations:
                    summary: "A BOSH Director is down"
                    description: |
                      Losing the BOSH Director does not significantly impact the experience of Tanzu Application Service end users. However, this issue means a loss of resiliency for BOSH-managed VMs.

                      Troubleshooting Steps:
                      SSH into the `bosh-health-exporter` VM in the "Healthwatch Exporter" deployment, and view logs to find out why the BOSH Director is failing.
            - name: CertificateExpiration
              rules:
                - alert: ExpiringCertificate
                  expr: "ssl_certificate_expiry_seconds < 2592000"
                  for: 5m
                  annotations:
                    summary: "A certificate is expiring"
                    description: |
                      At least one certificate ({{ $labels.display_name }}) on your foundation is going to expire within 30 days.
            - name: OpsManagerHealth
              rules:
                - alert: OpsManagerStatus
                  expr: 'probe_success{instance="<OPS_MANAGER_URL>"} <= 0'
                  for: 10m
                  annotations:
                    summary: "The Ops Manager health check failed"
                    description: |
                      Issues with Ops Manager health should have no direct end user impacts, however it can can impact an operator�셲 ability to perform an upgrade or to rescale the Tanzu Application Service platform when necessary.
            ##### END FOUNDATION ALERTING RULES #####

            ##### BEGIN TAS ALERTING RULES #####
            - name: TanzuApplicationServiceSLOs
              rules:
                - alert: TanzuSLOCFPushErrorBudget
                  expr: '( (1 - (rate(tas_sli_task_failures_total{task="push"}[28d]) / rate(tas_sli_task_runs_total{task="push"}[28d]) ) ) - 0.99) * (28 * 24 * 60) <= 0'
                  for: 15m
                  annotations:
                    summary: "The `cf_push` command is unresponsive"
                    description: |
                      This alert fires when the error budget reaches zero.

                      This commonly occurs when:
                      - Diego is under-scaled
                      - UAA is unresponsive
                      - Cloud Controller is unresponsive

                      Check the status of these components in order to diagnose the issue.
                - alert: TanzuSLOCFPushAvailability
                  expr: 'rate(tas_sli_task_failures_total{task="push"}[5m:15s]) * 300 > 0'
                  for: 10m
                  annotations:
                    summary: "The `cf_push` command is unresponsive"
                    description: |
                      This alert fires when the command has been unresponsive for 10 minutes.

                      This commonly occurs when:
                      - Diego is under-scaled
                      - UAA is unresponsive
                      - Cloud Controller is unresponsive

                      Check the status of these components in order to diagnose the issue.
                - alert: TanzuSLOCanaryAppErrorBudget
                  expr: "( (avg_over_time(probe_success[28d]) - 0.999) * (28 * 24 * 60) ) <= 0"
                  for: 10m
                  annotations:
                    summary: "Your Error Budget for your Canary URLs is below zero"
                    description: |
                      This alert fires when your error budget for your Canary URLs is below zero.
                      If your Canary URLs are representative of other running applications, this could indicate that your end users are affected.

                      Recommended troubleshooting steps:
                      Check to see if your canary app(s) are running. Then check your foundation's networking, capacity, and VM health.
                - alert: TanzuSLOCanaryAppAvailability
                  expr: "avg_over_time(probe_success[5m]) < 1"
                  for: 1m
                  annotations:
                    summary: "Your Canary URL ({{ $labels.instance }}) is unresponsive"
                    description: |
                      The Canary URL ({{ $labels.instance }}) has been unresponsive for at least 5 minutes.
                      If your Canary URL is representative of other running applications, this could indicate that your end users are affected.

                      Recommended troubleshooting steps:
                      Check to see if your canary app(s) are running. Then check your foundation's networking, capacity, and VM health.
            - name: TASCLIHealth
              rules:
                - alert: TASCLICommandStatus
                  expr: "increase(tas_sli_task_failures_total[10m]) > 0"
                  for: 10m
                  annotations:
                    summary: "Healthwatch Tanzu Application Service CLI tests are failing"
                    description: |
                      One or more CLI tests have been failing for at least 10 minutes.
                      App Smoke Tests run every 5-minutes. When running HA, multiple smoke tests may run in the given 5-minutes. These tests are intended to give Platform Operators confidence that Application Developers can successfully interact with and manage applications on the platform.
                      Note: smoke tests will report a failure if any task (e.g. `push`, `login`) takes more than 5 minutes to complete.

                      Troubleshooting Steps:
                      If a failure occurs, attempt to use the failed CLI command in a terminal to see why it is failing.
            - name: TASDiego
              rules:
                - alert: TASDiegoMemoryUsed
                  expr: 'label_replace( (sum by (placement_tag) (CapacityTotalMemory) - sum by (placement_tag) (CapacityRemainingMemory) ) / sum by (placement_tag) (CapacityTotalMemory), "placement_tag", "cf", "placement_tag", "") > .65'
                  for: 10m
                  annotations:
                    summary: "Available memory for Diego Cells is running low"
                    description: |
                      You have exceeded 65% of your available Diego Cell memory capacity for ({{ $labels.placement_tag }}) for at least 10 minutes.
                      Low memory can prevent app scaling and new deployments. The overall sum of capacity can indicate that you need to scale the platform. It is recommended that you have enough memory available to suffer a possible failure of an entire availability zone (AZ). If following the best practice guidance of three AZs, your % available memory should always be at least 35%.

                      Troubleshooting Steps:
                      Assign more resources to the cells or assign more cells by scaling Diego cells in the Resource Config pane of the Tanzu Application Service tile.
                - alert: TASDiegoDiskUsed
                  expr: 'label_replace( (sum by (placement_tag) (CapacityTotalDisk) - sum by (placement_tag) (CapacityRemainingDisk) ) / sum by (placement_tag) (CapacityTotalDisk), "placement_tag", "cf", "placement_tag", "") > .65'
                  for: 10m
                  annotations:
                    summary: "Available disk for Diego Cells is running low"
                    description: |
                      You have exceeded 65% of your available Diego Cell disk capacity for ({{ $labels.placement_tag }}) for at least 10 minutes.
                      Low disk capacity can prevent app scaling and new deployments. The overall sum of capacity can indicate that you need to scale the platform. It is recommended that you have enough disk available to suffer a possible failure of an entire availability zone (AZ). If following the best practice guidance of three AZs, your % available disk should always be at least 35%.

                      Troubleshooting Steps:
                      Assign more resources to the cells or assign more cells by scaling Diego cells in the Resource Config pane of the Tanzu Application Service tile.
            - name: TASMySQLHealth
              rules:
                - alert: TASMySQLStatus
                  expr: "_mysql_available <= 0"
                  for: 10m
                  annotations:
                    summary: "The Tanzu Application Service MySQL database is not responding"
                    description: |
                      The MySQL database is used for persistent data storage by several Tanzu Application Service components. Note that this is the SQL database used by system components, not the MySQL service used by applications running on the platform.
                      Tanzu Application Service components that use system databases include the Cloud Controller, Diego Brain, Gorouter, and the User Authorization and Authentication (UAA) server.

                      Troubleshooting Steps:
                      Run mysql-diag and check the MySQL Server logs for errors.
            - name: TASRouter
              rules:
                - alert: TASRouterHealth
                  expr: 'system_healthy{exported_job="router", origin="bosh-system-metrics-forwarder"} <= 0 OR system_healthy{exported_job="router", origin="system_metrics_agent"} <= 0'
                  for: 10m
                  annotations:
                    summary: "The Tanzu Application Service Router is down"
                    description: |
                      The Tanzu Application Service Router being down prevents users from interacting with applications and services on the platform.

                      Troubleshooting Steps:
                      Review detailed Tanzu Application Service Router metrics and logs for details on the cause of the error.
                - alert: TASRouterCPUUtilization
                  expr: 'system_cpu_user{exported_job="router", origin="bosh-system-metrics-forwarder"} >= 80 OR system_cpu_user{exported_job="router", origin="system_metrics_agent"} >= 80'
                  for: 5m
                  annotations:
                    summary: "The Tanzu Application Service Router is experiencing average CPU utilization above 80%"
                    description: |
                      High CPU utilization of the Gorouter VMs can increase latency and cause throughput, or requests per/second, to level-off. It is recommended to keep the CPU utilization within a maximum range of 60-70% for best Gorouter performance.

                      Troubleshooting Steps:
                      Resolve high utilization by scaling the Gorouters horizontally, or vertically by editing the Router VM in the Resource Config pane of the Tanzu Application Service tile.
                - alert: TASRouterFileDescriptors
                  expr: "file_descriptors >= 90000"
                  for: 5m
                  annotations:
                    summary: "A Tanzu Application Service Router job has exceeded 90,000 file descriptors over the past 5 minutes"
                    description: |
                      The Tanzu Application Service Router on index ({{ $labels.index }}) has exceeded 90,000 file descriptors over the past 5 minutes.

                      File Descriptors are an indication of an impending issue with the GoRouter. Each incoming request to the router consumes 2 file descriptors. Without the proper mitigations, it could be possible for an unresponsive application to eventually exhaust the file descriptors in GoRouter, starving routes from other applications running on Tanzu Application Service.

                      Troubleshooting steps:
                      (1) Identify which app(s) are requesting excessive connections and resolve the impacting issues with these applications.
                      (2) If above recommended mitigations have not already been taken, do so.
                      (3) Consider adding more GoRouter VM resources to increase total available file descriptors.
            - name: TASUAA
              rules:
                - alert: TASUAAHealth
                  expr: 'system_healthy{exported_job="uaa", origin="bosh-system-metrics-forwarder"} <= 0 OR system_healthy{exported_job="uaa", origin="system_metrics_agent"} <= 0'
                  for: 10m
                  annotations:
                    summary: "A UAA VM has been unhealthy for 10 minutes"
                    description: |
                      The Tanzu Application Service UAA on index ({{ $labels.index }}) has been unhealthy for 10 minutes.
                      If UAA is down, developers and operators cannot authenticate to access the platform.

                      Troubleshooting steps:
                      - Scale the UAA VMs in BOSH
                      - See the [UAA Documentation](https://docs.run.pivotal.io/concepts/architecture/uaa.html) for more details and troubleshooting ideas.
            # APPLY THIS IF THE USAGE SERVICE IS DESIRED/INSTALLED
            - name: TASUsageService
              rules:
                - alert: TASUsageServiceEventProcessingLag
                  expr: 'sum(usage_service_app_usage_event_cc_lag_seconds) by (deployment) >= 172800'
                  for: 5m
                  annotations:
                    summary: "Usage Service has failed to fetch Events from Cloud Controller (CAPI) for the last 48 hours for the deployment ({{ $labels.deployment }}."
                    description: |
                      This is typically caused when Usage Service is running correctly, but can't reach CAPI. Common issues are Usage Service can not authenticate, Cloud Controller is in a bad state or the network settings are incorrectly set up.

                      Troubleshooting Steps:
                      - Check CAPI - Try `cf curl /v2/app_usage_events`. The response should be 200 with recent events as the payload.
                      - Check UAA - Make sure the Usage Service can authenticate with CAPI.
                      - Check the network settings.

                      * If the Usage Service fails to fetch events for 7 or more days, reach out to support.
                      **Data loss can occur if the Usage Service fails to fetch events for more than 29 days. **
                - alert: TASUsageServiceEventFetchingStatus
                  expr: 'sum(usage_service_app_usage_event_fetcher_job_exit_code) by (deployment) >= 1'
                  for: 6h
                  annotations:
                    summary: "Usage Service Event Fetching is failing for the deployment ({{ $labels.deployment }}."
                    description: |
                      Typically, this means the Usage Service is healthy, but CAPI is not returning the information that is being requested. Historically, this has happened either due to network failures, or the UAA component not authenticating the Usage Service application successfully.

                      Troubleshooting steps:
                      - Check to see if you are able to query CAPI for /v2/app_usage_events and /v2/service_usage_events using the `cf curl` command. A failure would indicate there is a problem outside of the Usage Service application affecting the health of the foundation.
                      - Check to see if UAA is working correctly.

                      * If the Usage Service Event Fetching is failing for more than 7 days, reach out to support immediately.
                      **Data loss can occur if Event Fetching fails for more than 29 days.**
            ##### END TAS ALERTING RULES #####

            ##### BEGIN HEALTHWATCH ALERTING RULES #####
            - name: HealthwatchTASSLOs
              rules:
                - alert: HealthwatchTASFunctionalExporter
                  expr: 'service_up{service="pas-sli-exporter"} < 1'
                  for: 10m
                  annotations:
                    summary: "The Healthwatch Tanzu Application Service Functional Exporter is down"
                    description: |
                      The Healthwatch Tanzu Application Service Functional Exporter has been down for 10 minutes.
                - alert: HealthwatchTASCounterExporter
                  expr: 'service_up{service="pas-exporter-counter"} < 1'
                  for: 10m
                  annotations:
                    summary: "The Healthwatch Tanzu Application Service Counter Exporter is down"
                    description: |
                      The Healthwatch Tanzu Application Service Counter Exporter has been down for 10 minutes.
                - alert: HealthwatchTASGaugeExporter
                  expr: 'service_up{service="pas-exporter-gauge"} < 1'
                  for: 10m
                  annotations:
                    summary: "The Healthwatch Tanzu Application Service Gauge Exporter is down"
                    description: |
                      The Healthwatch Tanzu Application Service Gauge Exporter has been down for 10 minutes.
                - alert: HealthwatchTASTimerExporter
                  expr: 'service_up{service="pas-exporter-timer"} < 1'
                  for: 10m
                  annotations:
                    summary: "The Healthwatch Tanzu Application Service Timer Exporter is down"
                    description: |
                      The Healthwatch Tanzu Application Service Timer Exporter has been down for 10 minutes.
            ##### END HEALTHWATCH ALERTING RULES #####

            ##### BEGIN MYSQL TILE ALERTING RULES #####
            - name: MySQLHealth
              rules:
                - alert: MySQLSingleNodeAndMultiSiteClusterHealth
                  expr: 'avg by (deployment) (_p_mysql_available unless on (index, deployment) _p_mysql_galera_wsrep_ready unless on (index, deployment) _p_mysql_follower_is_follower * on (index, deployment) (_p_mysql_system_persistent_disk_used_percent < bool 30) * on (index, deployment) (_p_mysql_system_ephemeral_disk_used_percent < bool 95) * on (index, deployment) (_p_mysql_performance_cpu_utilization_percent < bool 90) * on (index, deployment) system_healthy{exported_job=~".*mysql.*", deployment=~"service-instance.*", origin="bosh-system-metrics-forwarder"}) < 1'
                  for: 10m
                  annotations:
                    summary: "MySQL Single node or Multi-Site deployment has been unhealthy for 10 minutes"
                    description: |
                      One or more MySQL Single node or Multi-site cluster instances have been unhealthy for at least 10 minutes.
                      This may have an impact on applications connected to those databases.

                      Troubleshooting Steps:
                      - Check the MySQL Server logs for errors
                      - Check disk capacity
                      - Check CPU utilization
                      - See more at https://docs.pivotal.io/p-mysql/monitor.html and https://docs.pivotal.io/p-mysql/troubleshoot.html
                - alert: MySQLLeaderFollowerClusterHealth
                  expr: 'avg by (deployment) (_p_mysql_follower_slave_io_running * on (index, deployment) _p_mysql_follower_slave_sql_running * on (index, deployment) _p_mysql_available * on (index, deployment) (_p_mysql_system_persistent_disk_used_percent < bool 30) * on (index, deployment) (_p_mysql_system_ephemeral_disk_used_percent < bool 95) * on (index, deployment) (_p_mysql_performance_cpu_utilization_percent < bool 90) * on (index, deployment) system_healthy{exported_job=~".*mysql.*", deployment=~"service-instance.*", origin="bosh-system-metrics-forwarder"}) <= .5'
                  for: 10m
                  annotations:
                    summary: "MySQL Leader-Follower deployment has been unhealthy for 10 minutes"
                    description: |
                      One or more MySQL Leader-Follower cluster instances have been unhealthy for at least 10 minutes.
                      This may have an impact on applications connected to those databases.

                      Troubleshooting Steps:
                      - Check the MySQL Server logs for errors
                      - Run the inspect errand to see if nodes are correctly configured for replication
                      - Check disk capacity
                      - Check CPU utilization
                      - See more at https://docs.pivotal.io/p-mysql/monitor.html and https://docs.pivotal.io/p-mysql/troubleshoot.html
                - alert: MySQLHighAvailabilityClusterHealth
                  expr: 'avg by (deployment) (_p_mysql_galera_wsrep_ready * on (index, deployment) _p_mysql_available * on (index, deployment) (_p_mysql_system_persistent_disk_used_percent < bool 90) * on (index, deployment) (_p_mysql_system_ephemeral_disk_used_percent < bool 95) * on (index, deployment) (_p_mysql_performance_cpu_utilization_percent < bool 90) * on (index, deployment) system_healthy{exported_job=~".*mysql.*", deployment=~"service-instance.*", origin="bosh-system-metrics-forwarder"}) <= .67'
                  for: 10m
                  annotations:
                    summary: "MySQL High Availability deployment has been unhealthy for 10 minutes"
                    description: |
                      One or more MySQL High Availability cluster instances have been unhealthy for at least 10 minutes.
                      This may have an impact on applications connected to those databases.

                      Troubleshooting Steps:
                      - Check the MySQL Server logs for errors
                      - Run mysql-diag on the mysql-jumpbox instance for the cluster to check the cluster's state
                      - Ensure no infrastructure event is affecting intra-cluster communication
                      - Check disk capacity
                      - Check CPU utilization
                      - See more at https://docs.pivotal.io/p-mysql/monitor.html and https://docs.pivotal.io/p-mysql/troubleshoot.html
            ##### END MYSQL TILE ALERTING RULES #####

            ##### BEGIN RABBITMQ ALERTING RULES #####
            - name: RabbitMQHealth
              rules:
                - alert: RabbitMQClusterHealth
                  expr: 'avg by (deployment) (min by (deployment, index) ( (1 - _p_rabbitmq_rabbitmq_system_disk_free_alarm) or (1 - _p_rabbitmq_rabbitmq_system_mem_alarm ) or system_healthy{origin="bosh-system-metrics-forwarder", exported_job=~"rabbitmq-server|rabbitmq-haproxy"} or (_p_rabbitmq_rabbitmq_erlang_reachable_nodes == bool on (deployment) group_left count(system_healthy{origin="bosh-system-metrics-forwarder"}) by (deployment) ) ) ) < .5'
                  for: 5m
                  annotations:
                    summary: "At least 50% of RabbitMQ nodes for a deployment are down"
                    description: |
                      View the RabbitMQ Details dashboard in order to diagnose the issue for the ({{ $labels.deployment }}) deployment.
            ##### END RABBITMQ ALERTING RULES #####
        enable_rabbitmq_scrape_config: false
        evaluation_interval: 15s
        log_level: debug
        remote_write:
          configs: []
        scrape_configs:
          canary_exporter:
            address: 127.0.0.1:9115
            targets: []
          healthwatch_exporter:
            tls_config:
              ca: |
                -----BEGIN CERTIFICATE-----
                MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
                CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
                MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
                dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
                FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
                yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
                P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
                w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
                46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
                xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
                MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
                AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
                BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
                YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
                Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
                wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
                Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
                +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
                -----END CERTIFICATE-----
              certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/healthwatch_exporter_client_mtls.cert_pem))
              key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/healthwatch_exporter_client_mtls.private_key_pem))
          jobs: []
          opsman_skip_ssl_validation: false
          opsman_url: null
          pks_cluster_discovery:
            tls_config:
              ca: |
                -----BEGIN CERTIFICATE-----
                MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
                CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
                MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
                dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
                FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
                yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
                P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
                w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
                46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
                xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
                MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
                AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
                BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
                YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
                Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
                wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
                Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
                +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
                -----END CERTIFICATE-----
              certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/cluster_discovery_client_mtls.cert_pem))
              key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/cluster_discovery_client_mtls.private_key_pem))
        scrape_interval: 15s
        storage:
          persistent_disk_size_mb: 204800
          tsdb:
            retention: 42d
        tls_config:
          ca: |
            -----BEGIN CERTIFICATE-----
            MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
            CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
            MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
            dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
            FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
            yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
            P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
            w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
            46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
            xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
            MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
            AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
            BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
            YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
            Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
            wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
            Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
            +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
            -----END CERTIFICATE-----
          certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/tsdb_server_mtls.cert_pem))
          private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/tsdb_server_mtls.private_key_pem))
        web:
          enable_admin_api: true
          enable_lifecycle: true
          port: 9090
    provides: {}
    release: prometheus
  - consumes: {}
    name: prometheus_backup
    properties:
      tls:
        ca: |
          -----BEGIN CERTIFICATE-----
          MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
          CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
          MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
          dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
          FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
          yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
          P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
          w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
          46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
          xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
          MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
          AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
          BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
          YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
          Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
          wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
          Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
          +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
          -----END CERTIFICATE-----
        certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/tsdb_client_mtls.cert_pem))
        private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/tsdb_client_mtls.private_key_pem))
    provides: {}
    release: prometheus
  - consumes:
      nginx:
        from: tsdb-nginx
    name: nginx
    properties:
      instance_count: 2
      nginx:
        alertmanager_gossip_mtls:
          tls:
            ca: |
              -----BEGIN CERTIFICATE-----
              MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
              CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
              MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
              dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
              FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
              yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
              P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
              w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
              46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
              xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
              MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
              AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
              BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
              YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
              Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
              wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
              Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
              +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
              -----END CERTIFICATE-----
            client:
              certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/nginx_alertmanger_client_gossip_mtls.cert_pem))
              private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/nginx_alertmanger_client_gossip_mtls.private_key_pem))
            server:
              certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/nginx_alertmanger_server_gossip_mtls.cert_pem))
              private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/nginx_alertmanger_server_gossip_mtls.private_key_pem))
          upstream_port: 9094
        server_ports:
          alertmanager_gossip_mtls_local: 10403
          alertmanager_gossip_mtls_remote: 9098
          alertmanager_mtls: 9097
          promxy_mtls: 4450
        servers:
          alertmanager_mtls:
            ssl_verify_client: "on"
            tls:
              ca: |
                -----BEGIN CERTIFICATE-----
                MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
                CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
                MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
                dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
                FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
                yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
                P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
                w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
                46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
                xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
                MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
                AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
                BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
                YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
                Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
                wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
                Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
                +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
                -----END CERTIFICATE-----
              certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alertmanager_server_mtls.cert_pem))
              private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alertmanager_server_mtls.private_key_pem))
            upstream_port: 10401
          promxy_mtls:
            ssl_verify_client: "on"
            tls:
              ca: |
                -----BEGIN CERTIFICATE-----
                MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
                CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
                MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
                dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
                FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
                yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
                P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
                w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
                46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
                xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
                MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
                AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
                BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
                YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
                Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
                wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
                Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
                +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
                -----END CERTIFICATE-----
              certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/promxy_server_mtls.cert_pem))
              private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/promxy_server_mtls.private_key_pem))
            upstream_port: 8082
    provides:
      nginx:
        aliases:
        - domain: tsdb.service.healthwatch2.internal
        as: tsdb-nginx
        shared: true
    release: prometheus-nginx
  - consumes:
      alertmanager:
        from: alertmanager
    name: alertmanager
    properties:
      cluster:
        nginx_port: 10403
        port: 9094
      inhibit_rules: null
      instance_count: 2
      log_level: debug
      receivers:
        email_configs: []
        pagerduty_configs: []
        slack_configs:
        - basic_auth:
            secret: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alerting_slack_receiver_config/0/basic_auth.value))
          bearer_token:
            secret: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alerting_slack_receiver_config/0/bearer_token.value))
          ca: null
          guid: 4fee639a-d532-4f8c-9df6-cbae0620708c
          insecure_skip_verify: true
          receiver_config: 'channel: ''#development'''
          receiver_name: slack
          server_name: null
          slack_api_url:
            secret: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alerting_slack_receiver_config/0/slack_api_url.value))
          tls_certificates:
            cert_pem: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alerting_slack_receiver_config/0/tls_certificates.cert_pem))
            private_key_pem: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/alerting_slack_receiver_config/0/tls_certificates.private_key_pem))
        webhook_configs: []
      routes: |
        receiver: 'slack'
        group_by: [...]
        routes:
      web:
        port: 10401
    provides:
      alertmanager:
        as: alertmanager
    release: prometheus
  - consumes: {}
    name: promxy
    properties:
      healthwatch_deployment_name: p-healthwatch2-f1b02b35a93fdf6e7a9f
      healthwatch_network_name: tas-pcf-subnet-1
      instance_count: 2
      prometheus_web_port: 9090
      promxy:
        web:
          port: 8082
      tls:
        ca: |
          -----BEGIN CERTIFICATE-----
          MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
          CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
          MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
          dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
          FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
          yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
          P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
          w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
          46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
          xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
          MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
          AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
          BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
          YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
          Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
          wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
          Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
          +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
          -----END CERTIFICATE-----
        certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/tsdb_client_mtls.cert_pem))
        private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/tsdb_client_mtls.private_key_pem))
    provides: {}
    release: prometheus
  lifecycle: service
  name: tsdb
  networks:
  - default:
    - dns
    - gateway
    name: tas-pcf-subnet-1
  persistent_disk_type: "204800"
  properties: {}
  stemcell: bosh-aws-xen-hvm-ubuntu-xenial-go_agent
  update:
    max_in_flight: 1
  vm_type: c5.xlarge
- azs:
  - ap-northeast-1a
  env:
    bosh:
      password: $6$c2befebf9aac277c$gUem0AzRtb3o2oPGN.WTmEabnadFzhBJQ1QStnl/MRiB9hK7g6yfGWW4VhRWR7oUI2yVKk.87S6JeT24DF5Bd/
  instances: 1
  jobs:
  - consumes:
      proxy:
        from: proxy
      tsdb-nginx:
        from: tsdb-nginx
    name: grafana
    properties:
      grafana:
        auth:
          basic:
            enabled: true
          enable_login_form: true
          generic_oauth:
            allow_sign_up: true
            allowed_domains: null
            allowed_groups: null
            allowed_organizations: null
            api_url: http://localhost:3002/userinfo
            auth_url: https://uaa.sys.leedh.cloud/oauth/authorize
            client_id: grafana
            client_secret: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana_authentication/uaa/client_secret.value))
            email_attribute_name: null
            enabled: true
            hosted_domain: null
            name: UAA
            root_url: https://uaa.sys.leedh.cloud
            scopes:
            - openid
            - healthwatch.admin
            - healthwatch.edit
            - healthwatch.read
            send_client_credentials_via_post: false
            team_ids: null
            tls_config:
              ca: null
              certificate: null
              private_key: null
              skip_verify_insecure: true
            token_url: https://uaa.sys.leedh.cloud/oauth/token
          is_uaa: true
          ldap:
            enabled: false
        dashboards:
          discovery:
            enable_tas_tkgi: true
          enable_mysql: false
          enable_rabbitmq: false
        database:
          name: grafana
          password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_user.password))
          port: 3306
          server_cert_name: grafana_db
          tls:
            client_ca: |
              -----BEGIN CERTIFICATE-----
              MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
              CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
              MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
              dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
              FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
              yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
              P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
              w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
              46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
              xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
              MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
              AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
              BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
              YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
              Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
              wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
              Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
              +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
              -----END CERTIFICATE-----
            client_cert: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_client_certificate.cert_pem))
            client_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_client_certificate.private_key_pem))
          user: grafana
        disk_chunk_size: 6144
        explore:
          enabled: true
        memory_chunk_size: 4096
        promxy:
          enabled: true
          scrape_configs:
            canary_exporter:
              targets: []
            opsman_url: null
          tls:
            ca: |
              -----BEGIN CERTIFICATE-----
              MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
              CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
              MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
              dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
              FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
              yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
              P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
              w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
              46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
              xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
              MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
              AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
              BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
              YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
              Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
              wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
              Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
              +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
              -----END CERTIFICATE-----
            certificate: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/promxy_client_mtls.cert_pem))
            private_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/tsdb/promxy_client_mtls.private_key_pem))
        proxy: null
        security:
          admin_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/admin_login_password.password))
          admin_user: admin
          secret_key: ((ui_secret_key))
        server:
          root_url: http://grafana.leedh.cloud:443
        session:
          provider_name: grafana
          provider_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_user.password))
          provider_port: 3306
          provider_user: grafana
        smtp:
          enabled: false
        users:
          editors_can_admin: false
      healthwatch_deployment_name: p-healthwatch2-f1b02b35a93fdf6e7a9f
      healthwatch_network_name: tas-pcf-subnet-1
      opsman_access_credentials:
        hostname: 54.168.136.249
        port: 443
        uaa_client_name: restricted_view_api_access
        uaa_client_secret: 4f249fbfa8691aab9a0750b4e26e685b
    provides: {}
    release: grafana
  - consumes: {}
    name: reverse-proxy
    properties:
      additional_cipher: []
      grafana:
        auth:
          basic:
            enabled: true
          enable_login_form: true
          generic_oauth:
            allow_sign_up: true
            allowed_domains: null
            allowed_groups: null
            allowed_organizations: null
            api_url: http://localhost:3002/userinfo
            auth_url: https://uaa.sys.leedh.cloud/oauth/authorize
            client_id: grafana
            client_secret: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana_authentication/uaa/client_secret.value))
            email_attribute_name: null
            enabled: true
            hosted_domain: null
            name: UAA
            root_url: https://uaa.sys.leedh.cloud
            scopes:
            - openid
            - healthwatch.admin
            - healthwatch.edit
            - healthwatch.read
            send_client_credentials_via_post: false
            team_ids: null
            tls_config:
              ca: null
              certificate: null
              private_key: null
              skip_verify_insecure: true
            token_url: https://uaa.sys.leedh.cloud/oauth/token
          is_uaa: true
          ldap:
            enabled: false
      redirect_uri: http://grafana.leedh.cloud:443/login/generic_oauth
      target_url: http://localhost:3001
      telemetry_enabled: false
      tls_cert: null
      tls_key: null
    provides: {}
    release: grafana-auth-proxy
  - consumes: {}
    name: userinfo-proxy
    properties:
      grafana:
        auth:
          basic:
            enabled: true
          enable_login_form: true
          generic_oauth:
            allow_sign_up: true
            allowed_domains: null
            allowed_groups: null
            allowed_organizations: null
            api_url: http://localhost:3002/userinfo
            auth_url: https://uaa.sys.leedh.cloud/oauth/authorize
            client_id: grafana
            client_secret: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana_authentication/uaa/client_secret.value))
            email_attribute_name: null
            enabled: true
            hosted_domain: null
            name: UAA
            root_url: https://uaa.sys.leedh.cloud
            scopes:
            - openid
            - healthwatch.admin
            - healthwatch.edit
            - healthwatch.read
            send_client_credentials_via_post: false
            team_ids: null
            tls_config:
              ca: null
              certificate: null
              private_key: null
              skip_verify_insecure: true
            token_url: https://uaa.sys.leedh.cloud/oauth/token
          is_uaa: true
          ldap:
            enabled: false
      port: 3002
      telemetry_enabled: false
    provides: {}
    release: grafana-auth-proxy
  - consumes: {}
    name: bpm
    provides: {}
    release: bpm
  - consumes: {}
    name: configure-grafana
    properties:
      grafana:
        security:
          admin_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/admin_login_password.password))
    provides: {}
    release: grafana
  - consumes: {}
    name: database-backup-restorer
    provides: {}
    release: backup-and-restore-sdk
  - consumes:
      proxy:
        from: proxy
    name: grafana_backup
    properties:
      grafana:
        database:
          name: grafana
          password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_user.password))
          port: 3306
          tls:
            client_ca: |
              -----BEGIN CERTIFICATE-----
              MIIDUTCCAjmgAwIBAgIVAPrhX1AsD9IYfgy5AXaMwLa7enpeMA0GCSqGSIb3DQEB
              CwUAMB8xCzAJBgNVBAYTAlVTMRAwDgYDVQQKDAdQaXZvdGFsMB4XDTIxMDUzMDEy
              MTkwMloXDTI1MDUzMTEyMTkwMlowHzELMAkGA1UEBhMCVVMxEDAOBgNVBAoMB1Bp
              dm90YWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC7v1N9KoOIWDcp
              FEF47HsL0B7Ls6YYkZ5LN3hHiPNZQu5gQ41EBeAh+RAaKoPyBuOua1L4O47PI7bJ
              yKTDg9oecEmyBAeqZ1NiXOS0O7oewGOIpPMKLSnANC0MX3ulHLkXQcBaZSeBjHIX
              P23Q8jfi/ZFL1ILNq2xUssjRc+kXpHpKwgi402oIt0baVVraj8XjvlqY2tHcGmBv
              w8Q0231kSgEBcSvNtqAzpaSCvVrX1doQ17TBYVsUlKV5vMZDxG9eVliAZlb8elgF
              46+UllrHPB63JCB7LcZOtsybEa3YVO2gTfVMI8cmD9c6EjD9a5IOA2Q2xDWYzGAW
              xwkOCipvAgMBAAGjgYMwgYAwHQYDVR0OBBYEFNfvQPiiYoSRVo/vTFv+ngOKn02Z
              MB8GA1UdIwQYMBaAFNfvQPiiYoSRVo/vTFv+ngOKn02ZMB0GA1UdJQQWMBQGCCsG
              AQUFBwMCBggrBgEFBQcDATAPBgNVHRMBAf8EBTADAQH/MA4GA1UdDwEB/wQEAwIB
              BjANBgkqhkiG9w0BAQsFAAOCAQEAqNpvj0JYLfbcCFD7WmsQO5M/UeZlU76LsHh8
              YU2ztlt/JbEwZ2GBe0R3Gdewuqe0sj5Z6GCo+n0WH5WP2I0S3LnWMvdtSgcJW2//
              Sry1ciYiYbKYWZN3xejqBrU9H0zPNxX3jDts+ppFaIegV9KKALTXeT7EH8lGfeNA
              wP6nzv6klTOQg59W/4oA0x7vGZm115MxDC8zYKK/nICeN67ows4heTyu//D35UV5
              Y480IhM11drW103+8/dJPnAhiA/7tCHS4U9LEnFV8qZ9oFDGpv+OVUiyvVuKqwQI
              +5rbIrUWNFThfLtQfTL+fdKNrRLWAad+9MhkrthflsBupSU/Ig==
              -----END CERTIFICATE-----
            client_cert: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_client_certificate.cert_pem))
            client_key: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/mysql_client_certificate.private_key_pem))
          user: grafana
        security:
          admin_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/admin_login_password.password))
    provides: {}
    release: grafana
  - consumes: {}
    name: update-admin-password
    properties:
      grafana:
        auth:
          basic:
            enabled: true
          enable_login_form: true
          generic_oauth:
            allow_sign_up: true
            allowed_domains: null
            allowed_groups: null
            allowed_organizations: null
            api_url: http://localhost:3002/userinfo
            auth_url: https://uaa.sys.leedh.cloud/oauth/authorize
            client_id: grafana
            client_secret: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana_authentication/uaa/client_secret.value))
            email_attribute_name: null
            enabled: true
            hosted_domain: null
            name: UAA
            root_url: https://uaa.sys.leedh.cloud
            scopes:
            - openid
            - healthwatch.admin
            - healthwatch.edit
            - healthwatch.read
            send_client_credentials_via_post: false
            team_ids: null
            tls_config:
              ca: null
              certificate: null
              private_key: null
              skip_verify_insecure: true
            token_url: https://uaa.sys.leedh.cloud/oauth/token
          is_uaa: true
          ldap:
            enabled: false
        security:
          admin_password: ((/opsmgr/p-healthwatch2-f1b02b35a93fdf6e7a9f/grafana/admin_login_password.password))
          admin_user: admin
          secret_key: ((ui_secret_key))
    provides: {}
    release: grafana
  lifecycle: service
  name: grafana
  networks:
  - default:
    - dns
    - gateway
    name: tas-pcf-subnet-1
  persistent_disk_type: "5120"
  properties: {}
  stemcell: bosh-aws-xen-hvm-ubuntu-xenial-go_agent
  update:
    max_in_flight: 5
  vm_extensions:
  - vm-extension-grafana-6c91820847f501398b6b
  vm_type: m5.large
memo:
  comment: This entire section is just informational. It is NOT used by BOSH.
  ops_manager:
    overrides: []
name: p-healthwatch2-f1b02b35a93fdf6e7a9f
releases:
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: bpm
  url: file:///var/tempest/releases/bpm-1.1.9-ubuntu-xenial-621.64-20200924-161737-978137692.tgz
  version: 1.1.9
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: prometheus
  url: file:///var/tempest/releases/prometheus-2.1.1-build.4-ubuntu-xenial-621.64-20210506-155650-129077689.tgz
  version: 2.1.1-build.4
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: grafana
  url: file:///var/tempest/releases/grafana-2.1.1-build.4-ubuntu-xenial-621.64-20210506-155530-828393605.tgz
  version: 2.1.1-build.4
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: grafana-auth-proxy
  url: file:///var/tempest/releases/grafana-auth-proxy-2.1.1-build.4-ubuntu-xenial-621.64-20210506-155909-049011747.tgz
  version: 2.1.1-build.4
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: prometheus-nginx
  url: file:///var/tempest/releases/prometheus-nginx-2.1.1-build.4-ubuntu-xenial-621.64-20210506-155544-04260946.tgz
  version: 2.1.1-build.4
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: pxc
  url: file:///var/tempest/releases/pxc-0.33.0-ubuntu-xenial-621.64-20210224-223751-551849602.tgz
  version: 0.33.0
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: backup-and-restore-sdk
  url: file:///var/tempest/releases/backup-and-restore-sdk-1.18.3-ubuntu-xenial-621.64-20210202-160607-572786486.tgz
  version: 1.18.3
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: healthwatch-smoke-test
  url: file:///var/tempest/releases/healthwatch-smoke-test-2.1.1-build.4-ubuntu-xenial-621.64-20210506-155555-601105493.tgz
  version: 2.1.1-build.4
- exported_from:
  - os: ubuntu-xenial
    version: "621.64"
  name: pks-cluster-discovery
  url: file:///var/tempest/releases/pks-cluster-discovery-2.1.1-build.4-ubuntu-xenial-621.64-20210506-160126-967466704.tgz
  version: 2.1.1-build.4
stemcells:
- alias: bosh-aws-xen-hvm-ubuntu-xenial-go_agent
  os: ubuntu-xenial
  version: "621.117"
update:
  canaries: 1
  canary_watch_time: 30000-300000
  max_errors: 2
  max_in_flight: 1
  serial: true
  update_watch_time: 30000-300000
variables:
- name: ui_secret_key
  type: password
